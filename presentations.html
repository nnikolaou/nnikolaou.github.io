<!DOCTYPE html>
<html>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-79723811-1', 'auto');
  ga('send', 'pageview');
</script> 

	<head>
		<title>Nikolaos (Nikos) Nikolaou</title>
		<!-- link to main stylesheet -->
		<link rel="stylesheet" type="text/css" href="/css/main.css">
	</head>
	<body>
		<nav>
    		<ul>
        		<li><a href="/">Home</a></li>
	        	<li><a href="/cv">CV</a></li>
        		<li><a href="/publications">Publications</a></li>
            <li><a href="/presentations">Presentations</a></li>
        		<!--<li><a href="/blog">Blog</a></li>-->
    		</ul>
		</nav>
		<div class="container">
    		<div class="blurb">
        		<h1>Nikolaos (Nikos) Nikolaou</h1>
<h2>Selected Presentations</h2>

For paper presentations, go to the <a href="http://www.cs.man.ac.uk/%7Enikolaon/publications.html">publications</a> page.

<hr>
<br>
<br>


<big><big><b><font color="blue">2017</font></b></big></big></font>


<br>

<br><br><b><a href="%7Enikolaon_files/Imbalanced_Data_Full_Final.pdf" target="_blank">Learning from Imbalanced Classes: Problem Statement & Methods</a></b> 
<br>Talk contributed to Workshop on Class Imbalance in Machine Learning Classification, organized by the
<a href="http://www.physics.manchester.ac.uk/study/postgraduate/postgraduate-courses/4irdataintensivecdtphd/">
4IR STFC Centre for Doctoral Training in Data Intensive Science</a> of the University of Manchester, UK.

<br>


<br><br><b><a href="%7Enikolaon_files/Boosting_for_probability_estimation.pdf" target="_blank">Boosting for Probability Estimation & Cost-Sensitive Learning</a></b> 
<br>Lecture on the work I carried out during my PhD, along with online extensions and connections to other areas of machine learning I am currently exploring.
This is the full version of the talk (~ 1.5h). Appropriately adapted, shorter versions were delivered in:
<ul>
  <li>the Statistical Machine Learning group of the Department of Computing of the Imperial College London, UK</li>
  <li>the Department of Informatics and Telecommunications of the University of Athens, Greece</li>
  <li>the Department of Informatics of the Athens University of Economics and Business, Greece</li>
  <li>the Institute for Adaptive and Neural Computation of the Department of Informatics of the University of Edinburgh, UK</li>
  <li>the Department of Computer Science of the University of Cyprus, Cyprus</li>
  <li>the Electrical Engineering, Computer Engineering and Informatics of the Cyprus University of Technology, Cyprus</li>
  <li>the Greek Stochastics iota workshop, Greece.</li>
</ul>  

<hr>

<br>

<big><big><b><font color="blue">2015</font></b></big></big></font>


<br><br><b><a href="%7Enikolaon_files/Cost_sensitive_boosting_RS.pdf" target="_blank">Asymmetric boosting algorithms: Do we really need them?</a></b> 
<br>Lecture on my latest research delivered in the Research Symposium of the University of Manchester, UK. <!--For the updated version see the publications page.-->

<br><br><b><a href="%7Enikolaon_files/Cost_Sensitive_AdaBoost.pdf" target="_blank">Cost-sensitive learning with AdaBoost</a></b> 
<br>A brief introduction to cost-sensitive learning, followed by my latest research on cost-sensitive AdaBoost, delivered to the postgraduate class of <a href="https://studentnet.cs.manchester.ac.uk/pgt/COMP61011/" target="_blank">COMP61011: Foundations of Machine Learning</a> of the University of Manchester, UK.

<br><br><b><a href="%7Enikolaon_files/Optimal_Inductive_Inference_and_its_Approximations.pdf" target="_blank">Optimal inductive inference and its approximations</a></b> 
<br>Two-part talk on inductive inference delivered to the members of the <a href="http://mlo.cs.manchester.ac.uk/" target="_blank">Machine Learning and Optimization</a> research group of the University of Manchester, UK.
We first gave an intuitive interpretation of Solomonoff Induction, an intractable formalization of optimal inductive inference which combines ideas from philosophy, computer science, statistics & information theory.
We then saw how nature and machine learning overcome the ill-posedness of induction by introducing assumptions and settling for approximations. Concepts covered included: common assumptions, bias-variance
tradeoff, inductive bias & the no-free-lunch theorems, the role of Occam's Razor and elements of statistical learning theory.


<hr>

<br>

<big><big><b><font color="blue">2014</font></b></big></big></font>


<br><br><b><a href="%7Enikolaon_files/Introduction_to_AdaBoost.pdf" target="_blank">Introduction to AdaBoost</a></b> 
<br>Introductory lecture on AdaBoost delivered to the postgraduate class of <a href="https://studentnet.cs.manchester.ac.uk/pgt/COMP61011/" target="_blank">COMP61011: Foundations of Machine Learning</a> of the University of Manchester, UK.

<hr>
          
          
    		</div><!-- /.blurb -->
		</div><!-- /.container -->
		<footer>
    		<ul>
        		<li><a href="mailto:n.nikolaou@ucl.ac.uk">email</a></li>
        		<li><a href="https://github.com/nnikolaou">github.com/nnikolaou</a></li>
			</ul>
		</footer>
	</body>
</html>
